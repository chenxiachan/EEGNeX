{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81c12ab",
   "metadata": {},
   "source": [
    "*This is the open source code of paper: Toward reliable signals decoding for electroencephalogram: A benchmark study to EEGNeX.*<br>\n",
    "*@Date : 2022-05-29 18:31:45*<br>\n",
    "*@Author : Xia CHEN (xia.chen@iek.uni-hannover.de), Xiangbin Teng, Han Chen, Yafeng Pan, Philipp Geyer*<br>\n",
    "*@Link : http://arxiv.org/abs/2207.12369*<br>\n",
    "*@Ver : v01*<br>\n",
    "*For using the code or data, please cite:*<br>\n",
    "*- Chen, X., Teng, X., Chen, H., Pan, Y., & Geyer, P.. (2022). Toward reliable signals decoding for electroencephalogram: A benchmark study to EEGNeX.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66db90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import mean, std, dstack\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import tensorflow\n",
    "import torch\n",
    "import os, gc\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Selfbuilded functions\n",
    "from BenchmarkModels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook loads dataset in YourDataName.npy data format and run benchmarkmodels:\n",
    "- x_{}.npy (Input, format as #Samples, Channels, Lengths) \n",
    "- y_{}.npy (Label, num)\n",
    "\n",
    "'''\n",
    "\n",
    "DATA_LIST = ['YourDataName']\n",
    "channel_last=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(data):\n",
    "    print('Loading data', data)\n",
    "    X = np.load('x_{}.npy'.format(data))\n",
    "    y = np.load('y_{}.npy'.format(data))\n",
    "    # load input data\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix='', channel_last=False):\n",
    "    # X_SHAPE:  samples, channels, lengths\n",
    "    X, y = load_dataset_group(DATA)\n",
    "    # One hot encode y\n",
    "    y = to_categorical(y)\n",
    "    # TRAIN - 0.75. VALIDATION - 0.125, TEST - 0.125\n",
    "    trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.25)\n",
    "    valX, testX, valy, testy = train_test_split(testX, testy, test_size=0.5)\n",
    "    \n",
    "    print(trainX.shape, trainy.shape, valX.shape, valy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, valX, valy, testX, testy\n",
    "\n",
    "\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    "    return  m, s \n",
    "\n",
    "\n",
    "# Model traning/evaluating\n",
    "def model_evaluation(trainX, trainy, valX, valy, testX, testy, Model_name, Data_name, channel_last=False, plot_model=False):\n",
    "    \n",
    "    # Callbacks\n",
    "    callback_es = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "    callback_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    \n",
    "    checkpointDir = './model_weights/'\n",
    "    os.makedirs(checkpointDir, exist_ok=True)\n",
    "    checkpointPath = os.path.join(checkpointDir, \"{}_best_{}_weights.h5\".format(Data_name, Model_name))\n",
    "    checkpointer = ModelCheckpoint(filepath=checkpointPath, verbose=1, save_best_only=True)\n",
    "\n",
    "    # Params\n",
    "    verbose, epochs, batch_size = 0, 200, 128\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[2], trainX.shape[1], trainy.shape[1]\n",
    "\n",
    "    trainX = trainX.reshape((trainX.shape[0], 1, n_features, n_timesteps))\n",
    "    valX = valX.reshape((valX.shape[0], 1, n_features, n_timesteps))\n",
    "    testX = testX.reshape((testX.shape[0], 1, n_features, n_timesteps))\n",
    "\n",
    "    ### Model structure        \n",
    "    if(Model_name == 'Single_LSTM'):\n",
    "        model = Single_LSTM(n_timesteps, n_features, n_outputs)\n",
    "\n",
    "    if(Model_name == 'Single_GRU'):\n",
    "        model = Single_GRU(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    if(Model_name == 'OneD_CNN'):\n",
    "        model = OneD_CNN(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    if(Model_name == 'OneD_CNN_Dilated'):\n",
    "        model = OneD_CNN_Dilated(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    if(Model_name == 'OneD_CNN_Causal'):\n",
    "        model = OneD_CNN_Causal(n_timesteps, n_features, n_outputs)   \n",
    "        \n",
    "    if(Model_name == 'OneD_CNN_CausalDilated'):\n",
    "        model = OneD_CNN_CausalDilated(n_timesteps, n_features, n_outputs)   \n",
    "        \n",
    "    if(Model_name == 'TwoD_CNN'):\n",
    "        model = TwoD_CNN(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    if(Model_name == 'TwoD_CNN_Separable'):\n",
    "        model = TwoD_CNN_Separable(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    if(Model_name == 'TwoD_CNN_Dilated'):\n",
    "        model = TwoD_CNN_Dilated(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    if(Model_name == 'TwoD_CNN_Depthwise'):\n",
    "        model = TwoD_CNN_Depthwise(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    ###  \n",
    "    if(Model_name == 'Single_ConvLSTM2D'):\n",
    "        # reshape into subsequences (samples, time steps, rows, cols, channels)\n",
    "        trainX = trainX.reshape((trainX.shape[0], 1, 1, n_features, n_timesteps))\n",
    "        valX = valX.reshape((valX.shape[0], 1, 1, n_features, n_timesteps))\n",
    "        testX = testX.reshape((testX.shape[0], 1, 1, n_features, n_timesteps))\n",
    "    \n",
    "        model = Single_ConvLSTM2D(n_timesteps, n_features, n_outputs)\n",
    "    \n",
    "    if(Model_name == 'CNN_LSTM'):\n",
    "        model = CNN_LSTM(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    if(Model_name == 'CNN_GRU'):\n",
    "        model = CNN_GRU(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    ###\n",
    "\n",
    "    if(Model_name == 'EEGNet_8_2'):\n",
    "        model = EEGNet_8_2(n_timesteps, n_features, n_outputs)\n",
    "        \n",
    "    if(Model_name == 'test1'):\n",
    "        model = test1(n_timesteps, n_features, n_outputs) \n",
    "    if(Model_name == 'test2'):\n",
    "        model = test2(n_timesteps, n_features, n_outputs) \n",
    "    if(Model_name == 'test3'):\n",
    "        model = test3(n_timesteps, n_features, n_outputs) \n",
    "    if(Model_name == 'test4'):\n",
    "        model = test4(n_timesteps, n_features, n_outputs) \n",
    "        \n",
    "    if(Model_name == 'EEGNeX_8_32'):\n",
    "        model = EEGNeX_8_32(n_timesteps, n_features, n_outputs) \n",
    "\n",
    "    \n",
    "    if(plot_model==True):\n",
    "        print('The current running model is:', Model_name)\n",
    "        print(model.summary())\n",
    "    \n",
    "    \n",
    "    # Fit / Evaluate model\n",
    "    # Fit network callback_es, callback_lr\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose, \n",
    "              validation_data=(valX, valy), callbacks=[callback_es, callback_lr])\n",
    "\n",
    "    # Load optimal weights\n",
    "    # model.load_weights(checkpointPath)\n",
    "    # Evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    pred_i = model.predict(testX, batch_size=batch_size)\n",
    "    \n",
    "    return accuracy, pred_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785113e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for DATA in DATA_LIST:\n",
    "    # Log\n",
    "    path = 'ResultLog_{}.csv'.format(DATA)\n",
    "    now = datetime.now()\n",
    "    with open(path,'a', newline='') as f:\n",
    "        csv_write = csv.writer(f)\n",
    "        # Write a row of date dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        csv_write.writerow([dt_string])\n",
    "\n",
    "\n",
    "    Model_list = [\n",
    "                  'Single_LSTM', 'Single_GRU',\n",
    "                  'OneD_CNN', 'OneD_CNN_Dilated', \n",
    "                  'OneD_CNN_Causal', 'OneD_CNN_CausalDilated',\n",
    "                  'TwoD_CNN' ,'TwoD_CNN_Dilated', \n",
    "                  'TwoD_CNN_Separable','TwoD_CNN_Depthwise', \n",
    "                  'CNN_LSTM', 'CNN_GRU', \n",
    "                  'Single_ConvLSTM2D',\n",
    "                  'EEGNet_8_2',\n",
    "                  'EEGNeX_8_32',\n",
    "                  ]\n",
    "    \n",
    "    \n",
    "    # Clear cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print('='*20)        \n",
    "    # Load data\n",
    "    trainX, trainy, valX, valy, testX, testy = load_dataset(channel_last=channel_last)\n",
    "\n",
    "    \n",
    "    for Model_name in Model_list:\n",
    "        \n",
    "        scores = list()\n",
    "        pred = list()\n",
    "        true = list()\n",
    "        run_time = list()\n",
    "        \n",
    "        # Repeat experiment\n",
    "        for r in range(5):\n",
    "            if(r == 0):\n",
    "                score, pred_i = model_evaluation(trainX, trainy, valX, valy, testX, testy, Model_name, DATA, plot_model=True)\n",
    "            else:\n",
    "                score, pred_i = model_evaluation(trainX, trainy, valX, valy, testX, testy, Model_name, DATA)\n",
    "            score = score * 100.0\n",
    "            print('>#%d: %.3f' % (r+1, score))\n",
    "            scores.append(score)\n",
    "            pred.append(pred_i)\n",
    "            true.append(testy)\n",
    "        # Summarize results\n",
    "        mean_, std_ = summarize_results(scores)\n",
    "        print(\"Classification Report:\\n\", classification_report(np.argmax(testy, axis=1), np.argmax(pred_i, axis=1), digits=3))\n",
    "        \n",
    "        with open(path,'a', newline='') as f:\n",
    "            csv_write = csv.writer(f)\n",
    "            # Write data\n",
    "            csv_head = [Model_name, mean_, std_]\n",
    "            csv_write.writerow(csv_head)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
